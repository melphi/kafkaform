sources:
  - name: "raw__source__gdp__user__v1"
    config:
      connector.class: "io.confluent.kafka.connect.datagen.DatagenConnector"
      key.converter: "org.apache.kafka.connect.storage.StringConverter"
      max.interval: 1000
      quickstart: "users"
      kafka.topic: "raw__source__gdp__user__v1"
      value.converter": "io.confluent.connect.avro.AvroConverter"
      value.converter.schema.registry.url: "http://connect:8083"

streams:
  - name: "refined__stream__gdp__user__v1"
    sql: "CREATE STREAM refined__stream__gdp__user__v1 (userid VARCHAR KEY, regionid VARCHAR)
          WITH (KAFKA_TOPIC='raw__source__gdp__user__v1', PARTITIONS=2, REPLICAS=1, VALUE_FORMAT='AVRO');"

  - name: "refined__stream__gdp__user__v2"
    sql: "CREATE STREAM refined__stream__gdp__user__v2 (userid VARCHAR KEY, regionid VARCHAR)
          WITH (KAFKA_TOPIC='raw__topic__gdp__user__v2', PARTITIONS=2, REPLICAS=1, VALUE_FORMAT='AVRO');"

  - name: "refined__table__gdp__user__v1"
    sql: "CREATE TABLE refined__table__gdp__user__v1 AS SELECT userid, COUNT(*) AS TOTAL
          FROM refined__stream__gdp__user__v1 GROUP BY userid;"

  - name: "refined__stream__gdp__user_stats__v1"
    sql: "CREATE STREAM refined__stream__gdp__user_stats__v1
          AS SELECT refined__stream__gdp__user__v1.*
          FROM refined__stream__gdp__user__v1 refined__stream__gdp__user__v1
          JOIN refined__table__gdp__user__v1
            ON refined__stream__gdp__user__v1.userid = refined__table__gdp__user__v1.userid;"

  - name: "refined__query__gdp__user__v2"
    sql: "INSERT INTO refined__stream__gdp__user__v2
          SELECT *
          FROM refined__stream__gdp__user__v1;"

topics:
  - name: raw__topic__gdp__user__v1
    partitions: 3
    replicas: 1

  - name: raw__topic__gdp__user__v2
    partitions: 2
    replicas: 1
